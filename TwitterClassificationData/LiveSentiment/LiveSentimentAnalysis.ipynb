{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 recent tweets:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # General:\n",
    "# import tweepy           # To consume Twitter's API\n",
    "# import pandas as pd     # To handle data\n",
    "# import numpy as np      # For number computing\n",
    "# import csv\n",
    "# # For plotting and visualization:\n",
    "# from IPython.display import display\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# %matplotlib inline\n",
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib as mpl\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "# Twitter App access keys for @user\n",
    "\n",
    "# Consume:\n",
    "CONSUMER_KEY    = 'YdgIkIh9hUQo3KACKB0Su3Ixy'\n",
    "CONSUMER_SECRET = 'CqAQf68Zko4CDIefjvitMPX2hxQKsWjnELKOx09TMzrVJjkMi3'\n",
    "\n",
    "# Access:\n",
    "ACCESS_TOKEN  = '1233046286-I3HlD2UhO3sGZKWCEZGwn1xCpIW7n2Ljq83minp'\n",
    "ACCESS_SECRET = 'vm4VdOKIYMk0bh7QpBOuUt04qLrG4Xf8hHSKJyiWzl8D8'\n",
    "\n",
    "RECENT_TWEETS = 2000\n",
    "\n",
    "results = []\n",
    "\n",
    "# API's setup:\n",
    "def twitter_setup():\n",
    "    \"\"\"\n",
    "    Utility function to setup the Twitter's API\n",
    "    with our access keys provided.\n",
    "    \"\"\"\n",
    "    # Authentication and access using keys:\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "    auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "    # Return API with authentication:\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "\n",
    "# store to dataframe\n",
    "def tweets_df(results):\n",
    "    id_list = [tweet.id for tweet  in results]\n",
    "    data_set = pd.DataFrame(id_list, columns = [\"id\"])\n",
    "    \n",
    "    data_set[\"text\"] = [tweet.text for tweet in results]\n",
    "    data_set[\"created_at\"] = [tweet.created_at for tweet in results]\n",
    "    data_set[\"retweet_count\"] = [tweet.retweet_count for tweet in results]\n",
    "    data_set[\"user_screen_name\"] = [tweet.author.screen_name for tweet in results]\n",
    "    data_set[\"user_followers_count\"] = [tweet.author.followers_count for tweet in results]\n",
    "    data_set[\"user_location\"] = [tweet.author.location for tweet in results]\n",
    "    data_set[\"Hashtags\"] = [tweet.entities.get('hashtags') for tweet in results]\n",
    "    return data_set\n",
    "\n",
    "# We create an extractor object:\n",
    "extractor = twitter_setup()\n",
    "\n",
    "# We create a tweet list as follows:\n",
    "tweets = tweepy.Cursor(extractor.search,q=\"#LACvsBAL\",count=2000,lang=\"en\",since=\"2019-01-02\").items(RECENT_TWEETS)\n",
    "\n",
    "# #===================================================\n",
    "# # Download and save\n",
    "# # Open/Create a file to append data\n",
    "# csvFile = open('dataset-2019-01-02.csv', 'a')\n",
    "# #Use csv Writer\n",
    "# csvWriter = csv.writer(csvFile)\n",
    "# # tweepy.Cursor(extractor.search,q=\"#HappyNewYear2019\",count=1000000,lang=\"en\",since=\"2018-12-31\").items()\n",
    "# for tweet in tweets:\n",
    "# #     print (tweet.created_at, tweet.text)\n",
    "#     csvWriter.writerow([tweet.created_at, tweet.text.encode('utf-8')])\n",
    "# #===================================================\n",
    "\n",
    "# We print the most recent 5 tweets:\n",
    "print(\"{0} recent tweets:\\n\".format(RECENT_TWEETS))\n",
    "for tweet in tweets:\n",
    "    results.append(tweet)\n",
    "    \n",
    "print(\"Number of tweets extracted: {}.\\n\".format(len(results)))\n",
    "\n",
    "# print(results)\n",
    "data_set = tweets_df(results)\n",
    "display(data_set)\n",
    "\n",
    "# # Remove tweets with duplicate text\n",
    "\n",
    "text = data_set[\"text\"]\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    txt = ' '.join(word for word in text[i] .split() if not word.startswith('https:'))\n",
    "    data_set.set_value(i, 'text2', txt)\n",
    "    \n",
    "data_set.drop_duplicates('text2', inplace=True)\n",
    "data_set.reset_index(drop = True, inplace=True)\n",
    "data_set.drop('text', axis = 1, inplace = True)\n",
    "data_set.rename(columns={'text2': 'text'}, inplace=True)\n",
    "\n",
    "text = data_set[\"text\"]\n",
    "\n",
    "for i in range(0,len(text)):\n",
    "    textB = TextBlob(text[i])\n",
    "    sentiment = textB.sentiment.polarity\n",
    "    data_set.set_value(i, 'Sentiment',sentiment)\n",
    "    if sentiment <0.00:\n",
    "        SentimentClass = 'Negative'\n",
    "        data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
    "    elif sentiment >0.00:\n",
    "        SentimentClass = 'Positive'\n",
    "        data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
    "    else:\n",
    "        SentimentClass = 'Neutral'\n",
    "        data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
    "data_set.to_csv(\"TodayAnalysis.csv\")\n",
    "\n",
    "Htag_df = pd.DataFrame()\n",
    "j = 0\n",
    "\n",
    "for tweet in range(0,len(results)):\n",
    "    hashtag = results[tweet].entities.get('hashtags')\n",
    "    for i in range(0,len(hashtag)):\n",
    "        Htag = hashtag[i]['text'] \n",
    "        Htag_df.set_value(j, 'Hashtag',Htag)\n",
    "        j = j+1\n",
    "\n",
    "\n",
    "# Join all the text from the 1000 tweets\n",
    "Hashtag_Combined = \" \".join(Htag_df['Hashtag'].values.astype(str))\n",
    "\n",
    "no_millennials = \" \".join([word for word in Hashtag_Combined.split()\n",
    "                                if word != 'millennials'\n",
    "                                and word != 'Millennials'\n",
    "                                and word != 'Boomers'\n",
    "                                and word != 'GenX'\n",
    "                                                                \n",
    "                                ])\n",
    "\n",
    "Tweet_mask = imread(\"./twitter_mask.png\", flatten=True)\n",
    "\n",
    "#Create a Word Cloud\n",
    "wc = WordCloud(background_color=\"white\", stopwords=STOPWORDS, mask = Tweet_mask)\n",
    "wc.generate(no_millennials)\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('./Todays_Hashtag.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
